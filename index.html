---
layout: single
title: "Haoyu Chen"
author_profile: true
header:
  overlay_image: "/assets/images/hero/header.jpg"
  overlay_filter: 0.35  # 0.0 ~ 1.0, 数值越大越暗
  overlay_height: 650px
  caption: "Haoyu Chen — Learning-Enhanced Autonomous Systems"
---

<h2>About Me</h2>

<p>
        I am a third-year undergraduate student at <strong>Westlake University</strong>, currently a visiting research student at the <strong>ICON Lab, UC Berkeley</strong>, working with Dr. Negar Mehr. Since my first year, I have been conducting research in the <strong>WINDY Lab</strong> under Prof. Shiyu Zhao.
    </p>

    <p>
        My research focuses on <strong>learning-enhanced autonomous systems</strong>&mdash;methods that combine <em>structured sensing and estimation</em> with <em>modern generative learning</em> to build autonomous robots that operate reliably in the real world. I am especially interested in systems that integrate:
    </p>

    <ul>
        <li><strong>structured sensor models</strong> (photometric ranging, bearing-strength estimation),</li>
        <li><strong>estimation and safety</strong> (pseudo-linear filters, observability), and</li>
        <li><strong>data-driven planning</strong> (diffusion-based imitation learning, world models).</li>
    </ul>

    <p>
        I particularly enjoy research that blends <strong>clear physical models</strong> with <strong>real robotic deployment</strong>. My work spans real-world multi-robot systems (Infra-Swarm), structure-aware estimation methods, and learning-based planners for manipulation and multi-agent tasks.
    </p>

    <p>
        I plan to pursue a <strong>PhD in robotics, learning, and autonomy</strong> beginning in 2027.
    </p>


<hr>

<h2>Research</h2>

<h3>Infra-Swarm: Robust NIR-Based Multi-Robot Swarming (2023–Present)</h3>
<p><em>WINDY Lab @ Westlake University</em></p>
<p style="text-align: center;">
  <img 
    src="{{ '/assets/images/research/infra-swarm.jpg' | relative_url }}" 
    alt="Infra-Swarm near-infrared multi-robot swarming setup" 
    style="max-width: 600px; width: 100%; border-radius: 8px;"
  >
  <br>
  <span style="font-size: 0.9em; color: #666;">
    Infra-Swarm: 940nm NIR perception and multi-robot swarming platform.
  </span>
</p>
<ul>
  <li>Designed a full near-infrared (940nm) perception system using custom LED emitters, narrowband filters, and four grayscale cameras for 360° sensing.</li>
  <li>Built a photometric ranging model based on inverse-square law; calibrated using VICON ground truth; achieved centimeter-level accuracy.</li>
  <li>Developed distributed multi-target EKF tracking + optical UART communication protocol for low-cost inter-robot messaging.</li>
  <li>Demonstrated real-world flocking, formation transitions, and obstacle-aware coordination at 100 FPS.</li>
  <li><strong>Target venue:</strong> IEEE Transactions on Automation Science and Engineering (TASE).</li>
</ul>

<h3>Bearing-Strength Motion Estimation (2024–Present)</h3>
<p><em>WINDY Lab @ Westlake University</em></p>
<p style="text-align: center;">
  <img 
    src="{{ '/assets/images/research/bearing-strength.jpg' | relative_url }}" 
    alt="Bearing-strength motion estimation setup with cameras and IR emitters" 
    style="max-width: 600px; width: 100%; border-radius: 8px;"
  >
  <br>
  <span style="font-size: 0.9em; color: #666;">
    Bearing-strength estimation with grayscale cameras and IR emitters.
  </span>
</p>
<ul>
  <li>Proposed a pseudo-linear Kalman filter combining bearing and signal strength through an augmented emitter-power state.</li>
  <li>Derived observability conditions removing the classical lateral-motion requirement in bearing-only estimation.</li>
  <li>Built complete real-world evaluation pipeline with grayscale cameras and IR emitters.</li>
  <li><strong>ICRA resubmission in preparation.</strong></li>
</ul>

<h3>MIMIC-D: Diffusion-based Imitation Learning for Multi-Arm Planning (2025–Present)</h3>
<p><em>ICON Lab @ UC Berkeley</em></p>

<p style="text-align: center;">
  <img 
    src="{{ '/assets/images/research/MIMIC-D.png' | relative_url }}" 
    alt="MIMIC-D diffusion-based IL for manipulation" 
    style="max-width: 600px; width: 100%; border-radius: 8px;"
  >
  <br>
  <span style="font-size: 0.9em; color: #666;">
    MIMIC-D: Diffusion-based imitation learning for visual-conditioned multi-arm manipulation.
  </span>
</p>

<ul>
  <li>Developing <strong>MIMIC-D</strong>, a diffusion-based imitation-learning pipeline for multi-arm manipulation tasks.</li>
  <li>Building camera-based image-to-latent encoders and conditional diffusion policies for trajectory generation.</li>
  <li>Implementing dataset preprocessing, training scripts, and policy evaluation protocols.</li>
  <li>Studying how diffusion models capture multi-modal action distributions in manipulation tasks.</li>
</ul>

<hr>

<h3>DP-WM: Diffusion Policy + World Models for Real-Robot Planning (2025–Present)</h3>
<p><em>ICON Lab @ UC Berkeley</em></p>

<p style="text-align: center;">
  <img 
    src="{{ '/assets/images/research/DP-WM.png' | relative_url }}" 
    alt="Diffusion policy combined with world models for planning" 
    style="max-width: 600px; width: 100%; border-radius: 8px;"
  >
  <br>
  <span style="font-size: 0.9em; color: #666;">
    World-model–based prediction and long-horizon planning integrated with diffusion policies.
  </span>
</p>

<ul>
  <li>Working on world-model training and evaluation for predictive dynamics and multi-step rollout under uncertainty.</li>
  <li>Experimenting with video prediction, latent dynamics, and uncertainty-aware planning.</li>
  <li>Integrating diffusion policies with world models for long-horizon, closed-loop planning.</li>
  <li>Investigating how structured sensing (photometric ranging, bearing-strength) can serve as inputs to predictive models.</li>
</ul>


<h3>Voice-LLM Vehicle Control System (2023–2024)(In Chinese)</h3>
<p><em>WINDY Lab @ Westlake University</em></p>
<p style="text-align: center;">
  <iframe 
    src="https://player.bilibili.com/player.html?bvid=BV1RK421C7DF&vd_source=7efacd2eb444aa4c87b35be507842680" 
    width="100%" 
    height="400" 
    frameborder="0" 
    allowfullscreen
  ></iframe>
</p>
<ul>
  <li>Integrated Whisper STT + GPT-4 for natural-language vehicle control, achieving 92% intent recognition accuracy.</li>
  <li>Developed Unity simulation + deployed on physical mobile robots.</li>
</ul>

<hr>

<h2>Publications</h2>

<ul>
  <li>
    <strong>Infra-Swarm: Robust Vision-Based Multi-Robot Swarming via Near-Infrared Spectral Vision</strong><br>
    Haoyu Chen, Qijin Li, Wanyu Xiang, Yin Zhang, Zian Ning, Shiyu Zhao.<br>
    <em>Target: IEEE Transactions on Automation Science and Engineering (TASE).</em>
  </li>

  <li>
    <strong>A Bearing-Strength Method for Motion Estimation of Unknown Energy Emitters</strong><br>
    Zian Ning, Haoyu Chen, Yin Zhang, Shiyu Zhao.<br>
    <em>Submitted to ICRA 2024 (Rejected); under revision.</em>
  </li>
</ul>

<hr>

<h2>Selected Projects</h2>

<ul>
  <li><strong>Diffusion-based Planning for Multi-Robot Manipulation</strong><br>
    Conditional diffusion policy training with visual latent encoders.
  </li>

  <li><strong>Photometric Distance Estimation System</strong><br>
    Multi-sensor fusion + ISP calibration + VICON evaluation.
  </li>

  <li><strong>Multimodal Vehicle Control via LLMs</strong><br>
    Natural-language robot control using Whisper + GPT-4.
  </li>
</ul>

<hr>

<h2>Contact</h2>

<p>Email: <a href="mailto:chenhaoyu@westlake.edu.cn">chenhaoyu@westlake.edu.cn</a><br>
Westlake University / ICON Lab @ UC Berkeley</p>
